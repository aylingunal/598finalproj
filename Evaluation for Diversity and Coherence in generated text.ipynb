{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPxdw0K0GRRjp9r1IwcNWB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Distinct-1 and Distinct-2 for diversity, BERTScore for semantic coherence, and Self-BLEU to evaluate diversity negatively.\n","Additionally, I'll provide a simple example for a coherence metric such as the Lexical Chain Score."],"metadata":{"id":"bhXMf66J4GRY"}},{"cell_type":"markdown","source":["* Diversity Metrics (Distinct-1 & Distinct-2):\n","\n","These metrics are widely used to assess the variety in the generated text by calculating the ratio of unique unigrams (Distinct-1) and bigrams (Distinct-2) to the total number of words or bigrams. Higher values suggest greater diversity, indicating that the model can generate varied outputs rather than repeating the same phrases.\n","* BERTScore:\n","\n","BERTScore has become popular for its ability to use contextual embeddings (from models like BERT) to measure semantic similarity between the generated text and a reference. It's especially useful for assessing the coherence of the text, as it considers the contextual usage of words rather than just their presence.\n","\n","* Self-BLEU:\n","\n","Self-BLEU is often used to evaluate diversity negatively; it measures how similar different texts generated from the same model are to each other. Lower Self-BLEU scores are desirable as they indicate less repetition between different generated samples.\n","\n","* Coherence Metrics (Entity-based Coherence Score, Lexical Chain Score):\n","\n","Specialized coherence metrics analyze how logically connected and consistent the entities and their relationships are throughout the generated text. These metrics assess whether the text makes sense contextually and logically, which is crucial for tasks like story generation or lengthy descriptions in visual language models."],"metadata":{"id":"y-Doyszq4ueT"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfMwVee43oFu","executionInfo":{"status":"ok","timestamp":1714344195709,"user_tz":240,"elapsed":86778,"user":{"displayName":"xin jing","userId":"12344706376429156049"}},"outputId":"62beb58e-3e29-4729-d251-577c74e139ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m562.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.1+cu121)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.0.3)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.40.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.31.0)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.2.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n","Installing collected packages: portalocker, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n","Successfully installed bert-score-0.3.13 colorama-0.4.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 portalocker-2.8.2 sacrebleu-2.4.2\n"]}],"source":["!pip install bert-score nltk sacrebleu"]},{"cell_type":"code","source":["import nltk\n","from bert_score import score\n","import sacrebleu\n","from nltk.corpus import wordnet as wn\n","from nltk import pos_tag, word_tokenize\n","from nltk import ngrams, pos_tag, word_tokenize\n","from nltk.corpus import wordnet as wn\n","from bert_score import score"],"metadata":{"id":"NjdIVI1X3qYs","executionInfo":{"status":"ok","timestamp":1714344897120,"user_tz":240,"elapsed":108,"user":{"displayName":"xin jing","userId":"12344706376429156049"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Download necessary NLTK resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gXcCEDTy5F-h","executionInfo":{"status":"ok","timestamp":1714344455116,"user_tz":240,"elapsed":1545,"user":{"displayName":"xin jing","userId":"12344706376429156049"}},"outputId":"8d0344e7-f1da-469a-c793-371240b1ae61"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def calculate_diversity_metrics(texts):\n","    # Flatten the list of texts into a single list of tokens\n","    all_tokens = [token for text in texts for token in text.split()]\n","    unigrams = list(ngrams(all_tokens, 1))\n","    bigrams = list(ngrams(all_tokens, 2))\n","\n","    # Calculate Distinct-1 and Distinct-2\n","    distinct_1 = len(set(unigrams)) / len(unigrams) if unigrams else 0\n","    distinct_2 = len(set(bigrams)) / len(bigrams) if bigrams else 0\n","    return distinct_1, distinct_2\n","\n","def calculate_self_bleu(texts):\n","    # Self-BLEU is calculated by treating each sentence as a hypothesis and the rest as a reference\n","    scores = []\n","    for i in range(len(texts)):\n","        hypothesis = texts[i]\n","        references = texts[:i] + texts[i+1:]\n","        bleu = sacrebleu.corpus_bleu([hypothesis], [[ref] for ref in references])\n","        scores.append(bleu.score)\n","    return sum(scores) / len(scores) if scores else 0\n","\n","def calculate_bert_score(hypotheses, references):\n","    # Compute BERTScore\n","    P, R, F1 = score(hypotheses, references, lang=\"en\", rescale_with_baseline=True)\n","    return F1.mean().item()\n","\n","def lexical_chain_score(text):\n","    tokens = word_tokenize(text)\n","    tagged = pos_tag(tokens)\n","    nouns = [word for word, pos in tagged if pos.startswith('N')]\n","\n","    # Build chains based on WordNet synsets\n","    chains = []\n","    for noun in nouns:\n","        synsets = wn.synsets(noun, pos=wn.NOUN)\n","        if not synsets:  # If no synset is found, continue to the next noun\n","            continue\n","        added = False\n","        for chain in chains:\n","            # Check if any synset of the current noun matches any synset in the existing chains\n","            if any(syn in chain_synsets for syn in synsets for chain_synsets, _ in chain):\n","                chain.append((synsets, noun))\n","                added = True\n","                break\n","        if not added:\n","            chains.append([(synsets, noun)])\n","\n","    # Calculate the score based on chain length\n","    score = sum(len(chain) for chain in chains) / len(nouns) if nouns else 0\n","    return score\n"],"metadata":{"id":"leHPHVwv3ug-","executionInfo":{"status":"ok","timestamp":1714345046980,"user_tz":240,"elapsed":117,"user":{"displayName":"xin jing","userId":"12344706376429156049"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","texts = [\n","    \"the cat sits on the mat\",\n","    \"the cat plays with a ball\",\n","    \"a quick brown fox jumps over the lazy dog\",\n","    \"the quick brown fox is quick\"\n","    \"the quick brown fox jumps over the lazy dog and the quick brown fox was very quick\"\n","]\n","\n","distinct_1, distinct_2 = calculate_diversity_metrics(texts)\n","self_bleu = calculate_self_bleu(texts)\n","bert_score = calculate_bert_score(texts, texts)\n","lexical_chain = lexical_chain_score(' '.join(texts))  # Pass concatenated text to function\n","\n","print(f\"Distinct-1: {distinct_1:.2f}\")\n","print(f\"Distinct-2: {distinct_2:.2f}\")\n","print(f\"Self-BLEU: {self_bleu:.2f}\")\n","print(f\"BERTScore: {bert_score:.2f}\")\n","print(f\"Lexical Chain Score: {lexical_chain:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1cJd4oFc3wF0","executionInfo":{"status":"ok","timestamp":1714345059600,"user_tz":240,"elapsed":2399,"user":{"displayName":"xin jing","userId":"12344706376429156049"}},"outputId":"d7132a90-33c5-4cea-bef5-34177a0db72f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Distinct-1: 0.49\n","Distinct-2: 0.69\n","Self-BLEU: 39.26\n","BERTScore: 1.00\n","Lexical Chain Score: 1.00\n"]}]}]}